---
title: "Tester un projet sur du bare metal avec Github Actions et AWX"
date: 2021-01-20T11:10:24+02:00
tags:
  - ci
  - automatisation
  - energie
  - scaphandre
  - open-source
  - rust
  - rapl
  - tech
image: /github_awx.cleaned.png
thumbnail: /github_awx.cleaned.png
share_img: /github_awx.cleaned.png
author: Benoit Petit
---

Avec l'outillage actuel, notamment disponible en SaaS (Github Actions, GitlabCI, CircleCI, TravisCI, etc.), mettre en place des tests automatisés pour un projet est de plus en plus simple. Pour un petit projet, ça peut même être gratuit.

C'est en tout cas vrai pour les projets web ou les logiciels qui n'ont pas de pré-requis particuliers pour fonctionner. Ça l'est un petit peu moins pour les projets  un peu plus spécifiques, notamment ceux qui traitent de problématiques système ou sont proches du matériel. Un exemple bien connu est le noyau Linux. Avec tous les types de matériels supportés, vous imaginez bien qu'un système de Continuous Integration en SaaS (basée sur des machines virtuelles donc) ne suffirait pas.

## Le besoin

Je me suis retrouvé dans un cas de ce type, pour le développement de [scaphandre](https://github.com/hubblo-org/scaphandre) (bien que le projet soit bien plus simple et aucunement comparable à l'exemple précédent). Scaphandre permet de mesurer la consommation d'énergie d'une machine et de ses services. Pour ce faire,  nous utilisons [RAPL](https://01.org/blogs/2014/running-average-power-limit-%E2%80%93-rapl) (ou Running Average Power Limit), une technologie comprise dans la plupart des processeurs Intel et AMD, permettant de réguler la consommation d'énergie du CPU, de manière à éviter une surchauffe (pour simplifier). Pour ce faire il est logiquement nécessaire de mesurer cette consommation et ces métriques sont accessibles (Scaphandre fonctionne sur mon laptop).

Dès que l'on parle de machines virtuelles les choses se compliquent un peu. En effet les métriques de RAPL sont accessibles si l'on peut interagir avec l'OS d'une machine physique (puisque lui même interagit avec le processeur physique). Ce n'est pas le cas dans une machine virtuelle. Dans ce cas aussi Scaphandre peut apporter une réponse. Si il est installé sur l'hyperviseur, il est possible [de le déployer également dans les machines virtuelles]() et de transmettre, depuis la machine physique, les métriques de consommation qui concernent chaque VM. En tant que client d'un cloud privé, par exemple, on peut donc ensuite exploiter les métriques qui nous concernent, depuis la VM, comme si l'on était sur une machine physique.

Dans ce mode de fonctionnement, il est nécessaire d'avoir accès à une machine physique pour tester les nouvelles version du logiciel. Une fonctionnalité permettant d'[estimer la consommation](https://github.com/hubblo-org/scaphandre/issues/25), lorsque la mesure n'est pas possible, est à l'étude, mais dans tous les cas, il faut pouvoir tester toutes les fonctionnalitées.

## Des choix à faire

Le projet est hébergé sur Github. Utiliser Github Actions pour la CI semblait donc la choses la plus simple à faire. L'intégration des tests dans le workflow de développement est native et plutôt bien pensée.

Comment répondre au besoin de machine physique de test ? Il est possible de mettre en place un Github Actions runner chez soi et de le piloter depuis Github Actions, mais cette option ne me convenait pas pour plusieurs raisons.

La première est affichée sur la [documentation](https://docs.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners) de Github Actions: pour un dépot public, les forks du projet peuvent solliciter le runner. C'est un risque de sécurité évident.

La seconde raison est que ne suis pas à l'aise avec l'idée de lancer un runner qui ne fonctionne qu'avec Github. J'ai le sentiment (peut être un peu subjetif) que ça augmentera encore ma dépendance à Github vis à vis du projet. De plus, ça veut dire installer un service un peu obscur (bien qu'[open source]()) sur une machine qui pourrait faire bien d'autres choses (il est plus intéressant d'utiliser une machine au maximum de sa capacité plutôt que de sous utiliser plusieurs machines, en terme de sobriété numérique). Il serait certainement possible d'isoler ce service des autres, mais on en revient au premier problème (aucune garantie d'avoir un isolement suffisant si le service peut être détourné et compromettre les services voisins).

J'ai pensé à mettre en place Gitlab, GilabCI et un gitlab runner, mais ça me semblait overkill sachant que le projet est géré sur Github et qu'Actions est disponible. Dans un monde parfait je préferrerai tourner sur Gitlab, mais les raisons du choix de Github dépassent le cadre de ce post.

## Une vielle connaissance... qui a bien grandit !
  
Quelle solution permet de recevoir des instructions d'une chaine de CI et d'éxécuter des jobs dans différents contextes, en ayant accès au matériel, ou à des machines virtuelles (pour tester aussi l'[exporter Qemu](https://hubblo-org.github.io/scaphandre/references/exporter-qemu.html)), ou encore s'adapter à tout scénario possible de déploiement de scaphandre: Kubernetes, machines avec des processeurs d'architectures ou de marques différentes, serveurs embarquant des GPU, etc.) ? 

Quelle solution permet un contrôle total sur ce que font les jobs et permet de tester ces jobs en local ?

Assez de teasing, pour moi cette solution c'est [AWX](https://github.com/ansible/awx). J'utilise Ansible depuis plusieurs années et je suis toujours autant convaincu par cet outil. AWX, si vous ne connaissez pas encore, c'est la version communautaire d'[Ansible Tower](https://www.ansible.com/products/tower), la tour de contrôle d'ansible. Vos playbooks et role ansible dans des jobs et des workflows de CI et de CD ? Via une API qui peut aussi servir de point de contact dans n'importe quel contexte d'automatisation ? C'est possible. Dîtes bonjour à Ansible sous stéroides.

## Workflow Github Action

Voici à quoi ressemble le job de test côté Github Action:

{{< highlight yaml >}}
name: build_and_test

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]

jobs:
  build:
    name: build_and_test_x86_64
    runs-on: ubuntu-latest
    steps:
      - name: Install dependencies (awxkit) #1
        uses: actions/setup-python@v2
        with:
          python-version: '3.8.5'
      - name: Install python requirements (awxkit) #2
        run: |
          python -m pip install --upgrade pip
          pip install awxkit
      - name: Log on AWX #3
        id: login
        run: |
          export AWX_TOKEN=$(awx --conf.host ${{ secrets.AWX_HOST }} \
          	--conf.username ${{ secrets.AWX_USERNAME }} \
          	--conf.password ${{ secrets.AWX_PASSWORD }} \
          	login | jq .token | tr -d '"')
          echo "::set-output name=awx_token::${AWX_TOKEN}"
      - name: Launch job #4
        id: launch
        run: |
          awx --conf.token ${{ steps.login.outputs.awx_token }} \
           --conf.host ${{ secrets.AWX_HOST }} job_templates launch \
           --extra_vars="{\"github_repository\":\"${GITHUB_REPOSITORY}\",\"github_actor\":\"${GITHUB_ACTOR}\",\"github_workflow\":\"${GITHUB_WORKFLOW}\",\"github_workspace\":\"${GITHUB_WORKSPACE}\",\"github_event_name\":\"${GITHUB_EVENT_NAME}\",\"github_event_path\":\"${GITHUB_EVENT_PATH}\",\"github_sha\":\"${GITHUB_SHA}\",\"github_ref\":\"${GITHUB_REF}\",\"github_head_ref\":\"${GITHUB_HEAD_REF}\",\"github_base_ref\":\"${GITHUB_BASE_REF}\",\"github_server_url\":\"${GITHUB_SERVER_URL}\"}" \
           9 --monitor
{{</ highlight >}}

La première partie du fichier indique:
- le nom du workflow
- les conditions de déclenchement du workflow (ici: lors d'un push ou de la création d'une pull request sur les branches main ou dev)

La seconde partie comprend les jobs. Dans cet exemple, il n'y en a qu'un, il nous servira à build et tester scaphandre sur une machine avec un processeur intel x86_64. Ce job comprend les étapes suivantes dans l'ordre:

1. Demander python3 comme interpréteur python par défaut. C'est nécessaire pour AWXkit, le client en ligne de commande pour AWX. Notez que vous pouvez aussi bien écrire directement vos scripts pour discuter avec l'API d'AWX, j'ai choisi la simplicité.
2. Installer les dépendances nécessaires: awxkit.
3. S'authentifier auprès de l'API d'AWX.  
	1. La commande `export` place dans l'environnement local du runner le résultat de la commande `awx login`. `jq` et `tr` sont là pour extraire uniquement le token résultant, qui nous servira pour authentifier nos requetes par la suite.
	2. On rend accessible le token aux autres steps avec la commande set-output. (Notez que l'on a identifié la step au préalable avec `id: login`)
4. Lancer le job en faisant appel à AWX. On utilise le token de l'étape précédente avec `steps.login.outputs.awx_token`. Plusieurs informations sur l'évennement qui déclenche le job sont passé en `extra_vars`. Ce sont les variables [disponibles par défaut dans l'environement](https://docs.github.com/en/actions/reference/environment-variables#default-environment-variables) Github Actions. Les indispensables notre cas sont:
	1. `GITHUB_REPOSITORY`: Le nom du dépot au format `ORGANISATION/DEPOT`
	2. `GITHUB_SHA`: Le hash sha-1 qui identifie le commit correspondant au push ou à la pull-request d'origine.
	3. `GITHUB_REF`: La refspec. C'est une information supplémentaire nécessaire au module `git` d'ansible, dans certains cas. On y reviendra.
  
  Dans cette dernière step, on utilise un numéro/id pour identifier le job à lancer, il faut donc repérer son numéro au préalable, soit en naviguant dans l'api via un navigateur sur `https://monawx.quelquepart/api/v2/` ou toujours avec awxkit et la commande `awx job_templates list`. L'option `--monitor` est pratique car elle va attendre que le job soit terminé pour afficher la trace d'exécution et retourner le résultat (et donc valider ou faire échouer le workflow github action en fonction). Pas besoin donc de coder une boucle pour attendre le résultat, awxkit s'en charge pour nous (l'option `--wait` est équivalente, mais n'affiche pas la trace d'exécution).
  
## Le job AWX

Je vais passer ici la phase d'installation d'AWX pour limiter la taille de l'article.

Une fois votre service en place, il faut définir

